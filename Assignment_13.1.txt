1. What is RDD?
   RDD’s(Resilient Distributed Dataset) in Spark are immutable distributed collection of objects.
   Each RDD is split into multiple partitions, which may be computed on different
   nodes of the cluster.
   They are not actual data, but they are Objects, which contain information about
   data residing on the cluster.
   The RDDs try to solve these problems by enabling fault tolerant, distributed In-
   memory computations.
   
2. Define Partitions.
   Partition is a logical chunk of a large distributed data set.
   RDDs are collections of objects. Under the hood, these objects are stored in partitions. 
   When performing computations on RDDs, these partitions can be operated on in parallel.

3. What operations does RDD support?
   RDDs perform two types of operations: Transformations, which creates a new dataset from
   the previous RDD and Actions, which return a value to the driver program after performing
   the computation on the dataset.
   RDDs keeps track of Transformations and check them periodically. If a node fails, it can rebuild
   the lost RDD partition on the other nodes, in parallel.

4. What do you understand by Transformations in Spark?
   Transformations, which creates a new dataset from the previous RDD.

5. Define Actions.
   Actions, which return a value to the driver program after performing the computation on the dataset.